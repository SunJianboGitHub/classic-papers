# <div align="center">Focal Loss损失函数🚀</div>
☘️🌟🚀🔥
1. 前言
2. 问题的提出
3. Focal Loss损失函数🔥🔥🔥
4. 检测头参数初始化🔥🔥🔥
5. 一些疑惑的问题🔥🔥🔥🔥🔥
6. 总结
7. 参考博客

## <div align="left">0. 什么是正负样本、难易样本？🚀</div>

<div align="center">
    <img src=./images/positive-negative.png width=80% >
</div>

- 正样本： 与真值对应的目标类别来说该样本为正样本。
- 负样本： 与真值不对应的其他所有目标类别来说该样本为负样本。
- 困难样本： 预测时与真值标签误差较大的样本。
- 简单样本： 预测时与真值标签误差较小的样本。


## <div align="left">1. 前言🚀</div>

原论文的题目叫作《Focal Loss for Dense Object Detection》。这篇文章主要是介绍了一种特殊的损失函数Focal Loss，RetinaNet只是作者为了证明Focal Loss有效而专门搭建的一个单阶段目标检测器。为了提升训练初期的稳定性，这篇文章还介绍了检测层的参数初始化方法，可以推广使用。

[论文链接: Focal Loss for Dense Object Detection](https://arxiv.org/pdf/1708.02002.pdf)
[代码链接](https://github.com/facebookresearch/Detectron)



## <div align="left">2. 问题的提出🚀</div>

通过之前的学习我们知道，目标检测方法大致可以分为两类：单阶段和两阶段。其中，单阶段的方法虽然较为简单且速度块，但是其**检测精度要比两阶段的方法低**。造成这一现象的原因是单阶段的方法往往在训练密集检测器时前景与背景类的数量极度不平衡。**那么为什么会造成类别不平衡问题呢？两阶段又是如何在一定程度上避免这个问题的呢？**

- 1. 类别不平衡的形成原因是图片中的物体框数量一般来说都小于背景框数量，也就是说不是所有的框都能检测出物体
- 2. 两阶段的目标检测算法通过候选框算法(proposal stage)过滤了大部分背景样本(负样本)，使得正负样本比例适中。
- 3. 单阶段的目标检测算法，需要处理大量的负样本，使得包含目标的正样本信息被淹没，这使得单阶段的目标检测算法识别精度比不上两阶段的目标检测算法。

**单阶段目标检测算法存在的问题**

- 1. 一张图像中，目标所占的比例远远小于背景类所占的比例，所以两类候选框中以negative example为主。
- 2. 针对所有的negative example，由于数量过多造成它的loss太太，以至于主导了损失函数，淹没了positive example的作用，不利于模型收敛。
- 3. 针对单个negative example来说，单个example的loss很小，反向计算时梯度小。梯度小造成easy negative example对参数的收敛作用很有限，我们需要loss大的对参数收敛影响也更大的example，即hard positive/negative example。（大概意思就是一个中学生，如果你一直叫他去写小学生的卷子，那么他的成绩不会提升，如果叫他写很难的卷子，这样会很打击他的信心，要有个权衡）



## <div align="left">3. Focal Loss损失函数🔥🔥🔥</div>

下图中，最上面的蓝色线的是指交叉熵(CE)损失曲线。这个CE损失曲线的一个显著特征是，虽然那些容易分类的样本(p >= 0.5)，产生的损失很小，但是当大量易分类样本结合后，这些损失可以完全压制困难样本。也就是说**因为在我们训练过程中，检测到的大多数样本都属于容易识别的样本，即负样本(又称背景)，虽然这些样本的CE损失值相对于目标样本的CE损失小，但是背景样本往往比具有目标的样本多几十倍、甚至更多，所以算总CE损失时，含有目标样本的损失往往要小于背景样本的CE损失，这就会导致含有目标样本的作用微乎其微。**

<div align="center">
    <img src=./images/focal_loss.jpg width=50% >
</div>



为了解决上述问题，Focal Loss使用了动态加权的思想。

- **1. 解决样本类别不平衡:** 我们使用一个平衡因子$\alpha$, 其范围是[0,1]，对于类别1乘以$\alpha$，而对于类别为-1的样本乘以$1-\alpha$。虽然$\alpha$平衡了正负样本的数量，但是实际上，目标检测中大量的候选目标都是易分样本(大部分是负样本)。这样样本的损失很低，但是由于数量的极度不平衡，易分样本的数量相对来讲太多，最终主导了总的损失。**为了平衡正负样本均衡，$\alpha=0.75$才是最合适的(正负样本比例1:3)，但是最后论文中选取的确实$\alpha=0.25$，反而是正样本的系数更小。其实这里不能单看$\alpha$这一个参数，它是和$\gamma$参数一起起作用的。具体可以参看第五部分的解释。**


- **2. 解决难易样本不平衡:** 对于置信度高的样本，损失函数进行降权；对于置信度低的样本，损失函数进行加权，使得网络在反向传播时，置信度低的样本能够提供更大的梯度占比，即从未学习好的样本中获取更多的信息。**就像高中时期的错题本一样，对弈容易错的题目，包含了更多的信息量，需要更加关注这种题目；而对于屡屡正确的题目，可以少关注点，说明已经掌握了这类型的题目。**

这篇文章的巧妙之处是，通过网络本身输出的概率值(置信度)去构建权重，实现了自适应调整权重的目的。

#### Focal Loss的公式如下：

Focal Loss是基于交叉熵损失函数构建的，二元交叉熵损失的公式为：
$$CE(p, y) = \begin{cases}
-log(p), & \text{if  y = +1}  \\
-log(1-p), & \text{if y = -1} \\
\end{cases}$$

为了方便表示，应以pt为分类正确的概率

$$p_t = \begin{cases}
p, & \text{if y = +1}  \\
1-p, & \text{if y = -1} 
\end{cases}$$


则二元交叉熵表示为$CE(p, y) = CE(p_t) = -log(p_t)$。如前文所述，通过置信度对损失进行缩放得到Focal Loss。

$$FL(p_t) = -\alpha_t(1 - p_t) ^ {\gamma}log(p_t) = \alpha_t(1 - p_t) ^ {\gamma} CE(p_t)$$

$$\alpha_t = \begin{cases}
\alpha, & \text{if y = +1} \\
1 - \alpha, & \text{if y = -1} \\
\end{cases}$$

其中，$\alpha_t$表示缩放系数(**调整正负样本的权重**)，$\gamma$表示缩放因子(**调整难易样本的权重**)。$(1 - p_t)$可以理解为分类错误的概率，公式中起到关键作用的部分是$(1 - p_t)^ \gamma$，为了给易分类样本降权，通常设置$\alpha=0.25$、$\gamma=2$。

- **对于易分类样本:** $p_t$趋近于1，$(1 - p_t)$趋近于0, $(1 - p_t) ^ \gamma$更趋近于0，对样本的CE损失值进行降权更大；
- **对于难分类样本:** $p_t$趋近于0，$(1 - p_t)$趋近于1, $(1 - p_t) ^ \gamma$也趋近于1，对样本的CE损失值进行降权很小；

**Focal Loss本质上是通过置信度给易分类样本进行更多降权，对难分类样本进行更少的降权，实现对难样本的关注。**


## <div align="left">4. 检测头参数初始化🔥🔥🔥</div>

论文中还有一个比较重要的点是对于子网络最后一层权重的初始化方式，这关系到网络初期的训练性能。这里结合论文和我看过的一篇博文进行详细展开。常规的深度学习网络初始化算法，使用的是高斯分布，根据概率论只是，两个高斯分布变量的乘积仍然服从高斯分布。假设权重$w \backsim N(\mu_w, \sigma_w ^{2})$，最后一层的特征$x \backsim N(\mu_x, \sigma_x ^ {2})$，则$w x \backsim N(\mu_{w x}, \sigma_{\mu x} ^ {2})$.

$$\mu_{wx} = \frac{\mu_w \sigma_x ^ {2} + \mu_x \sigma_w ^{2}}{\sigma_x ^ {2} + \sigma_w ^{2}}$$

$$\sigma_{wx} = \frac{\sigma_x ^ {2} \sigma_w ^{2}}{\sigma_x ^ {2} + \sigma_w ^{2}}$$


其中x的分布取决于网络的结果，$w$的分布参数为$\mu_w = 0, \sigma_w ^ {2} = 10 ^ {-4}$，只需要x的分布参数满足$\sigma_x ^ {2} \gg 10 ^ {-4}, \sigma_x ^ {2} \gg 10 ^ {-4} \mu_x$成立，有如下的不等式。(一般情况下，这两个条件是成立的。)

$$\mu_{wx} = \frac{\mu_w \sigma_x ^ {2} + \mu_x \sigma_w ^{2}}{\sigma_x ^ {2} + \sigma_w ^{2}} = \frac{10 ^ {-4} \mu_x} {\sigma_x ^ {2} + {10 ^ {-4}}} \ll \frac{10 ^ {-4} \mu_x}{10 ^ {-4} \mu_x + 10 ^ {-4}} = \frac{1}{1 + \frac{1}{\mu_x}} \approx 0$$


$$\sigma_{wx} = \frac{\sigma_x ^ {2} \sigma_w ^{2}}{\sigma_x ^ {2} + \sigma_w ^{2}} = \frac{10 ^ {-4}}{1 + \frac{10 ^ {-4}}{\sigma_x ^ {2}}} \approx 10^{-4}$$

根据上述推导，$wx$服从一个均值为0，方差很小的高斯分布，可以在很大概率上认为它就是0，所以网络最后一层的输出为
$$p = sigmoid(wx + b) = sigmoid(b) = \frac{1}{ 1 + e ^ {-b}} = \pi$$

令$\pi$为网络初始化时输出的正类概率，设置为一个很小的值(**p=0.01,采用反sigmoid求偏置的初始值为-4.59511985013459**)，则网络训练初期，将样本都划分为负类，对于正类$p_t = 0.01$，对于负类$p_t = 0.99$，则训练初期，正类被大概率错分，负类被大概率正确分类，所以在训练初期更加关注正类，避免初期正类信息被淹没在负类信息中。


## <div align="left">5. 一些疑惑问题🔥🔥🔥🔥🔥</div>

**1. 问题** : 在最后，这里对$\alpha=0.25$进行解释。为了解决正负样本类别不均衡，引入了$\alpha$参数，但是不是正样本少、负样本多吗？那为什么将0.25乘在正样本损失中，将0.75乘在负样本损失中，这样不是削弱了关注正样本吗？更不平衡了吗？

**1. 回答** : 单单考虑$\alpha$的话，$\alpha=0.75$时是最优的。但是将$\gamma$考虑进来后，因为已经降低了简单负样本的权重。$\gamma$越大，$\alpha$越小结果越好，最后选取$\alpha=0.25$、$\gamma=2$.

**2. 问题** : 那么$\alpha$的作用是不是可以理解为不能让容易分类的类别的损失函数太小，$\gamma$的作用是更加关注困难样本？

**2. 回答** : $\gamma$较大时，简单负样本的权重已经比较小了（负样本的影响力已经被削弱），所以$\alpha$相应减小来减小正样本的影响。$\alpha$和$\gamma$共同调节来达到一种相对平衡。 


## <div align="left">6. 总结</div>


总的来说，Focal Loss通过对损失函数的简单改进，实现了一种自适应的困难样本挖掘策略，使得网络在学习过程中关注更难学习的样本，在一定程度上解决了正负样本不均衡的问题(**由于正负样本不均衡，对于稀少的正样本的学习不足，导致正样本普遍表现为难样本**)。



## <div align="left">7. 参考博客🚀</div>


- [参考博客1: RetinaNet详解-附Pytorch代码讲解](https://blog.csdn.net/weixin_54546190/article/details/123558365)
- [参考博客2: Focal loss论文解析](https://www.cnblogs.com/kuadoh/p/13775379.html)
- [参考博客3: Focal Loss理解，这篇很重要🔥]((https://blog.csdn.net/qq_21539375/article/details/113967043))
- [参考博客4：Use Focal Loss To Train Model Using Imbalanced Dataset](https://leimao.github.io/blog/Focal-Loss-Explained/)








